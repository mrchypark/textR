---
title: "텍스트 분석을 위한 R"
author: "박찬엽"
date: "2018년 09월 18일"
output:
  xaringan::moon_reader:
    seal: false
    css: ["default", "custom.css"]
    lib_dir: libs
    includes:
      in_header: google_analytics.html
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(cache = T, fig.height = 5)
library(nycflights13)
```

class: center, middle, title-slide, 

## 텍스트 분석을 위한 R 

### <https://mrchypark.github.io/textR>

#### [[pdf버전]](https://github.com/mrchypark/textR/blob/master/docs/textR.pdf) [[문의하기]](http://pf.kakao.com/_RXANd) [[의견 및 오류 신고]](https://github.com/mrchypark/textR/issues/new)
#### [스타누르기](https://github.com/mrchypark/textR)는 컨텐츠 제작자를 춤추게 합니다.

### 박찬엽

### 2018년 09월 18일
---
class: center, middle, title-slide, 

## 텍스트 관련 R 패키지 설치 가이드

### <https://mrchypark.github.io/textR/installation>    

### [pdf 다운로드](https://github.com/mrchypark/textR/blob/master/docs/installation.pdf)

.footnote[\* R 3.5.1 을 기준으로 작성하였습니다.]

---
class: center, middle, title-slide, 

## 사전 지식 1
## 함수를 연결하는 파이프 연산자(%>%)

![](https://raw.githubusercontent.com/mrchypark/dabrp_classnote3/master/docs/img/pipes.png)

---

class: 
## 파이프 연산자(%>%)

함수를 중첩해서 사용할 일이 점점 빈번해 짐

```{}
plot(diff(log(sample(rnorm(10000,mean=10,sd=1),size=100,replace=FALSE))),col="red",type="l")
```

--
class: 
### %>%를 사용하면 

.pull-left[

1. 생각의 순서대로 함수를 작성할 수 있음
1. 중간 변수 저장을 할 필요가 없음
1. 순서가 읽이 용이하여 기억하기 좋음
]
.pull-right[
```{}
rnorm(10000,mean=10,sd=1) %>%
  sample(size=100,replace=FALSE) %>%
  log %>%
  diff %>%
  plot(col="red",type="l")
```
]
---
class: 

## 파이프 연산자(%>%)

flights 데이터에 파이프 연산자 사용예 1

```{r}
flights %>%
  group_by(year,month,day) %>%
  summarise(delay=mean(dep_delay, na.rm = TRUE))
```
---
class: 
## 파이프 연산자(%>%)

group_by()는 filter()와도 함께 사용할 수 있음

```{r}
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests

```

---
class: 
## 파이프 연산자(%>%)

사용할 데이터부터 순서대로 함수를 작성할 수 있는 장점

```{r}
popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
```

---

class: center, middle, title-slide, 

## 사전 지식 2
# tidy data + universe 

[![](https://github.com/tidyverse/tidyverse/raw/master/man/figures/logo.png)][1]

---
class: 
## [tidyverse][1] 패키지는

.pull-left[
1. RStudio가 개발, 관리하는 패키지    
1. 공식 문서가 매우 잘 되어 있음    
1. 사용자층이 두터워 영어로 검색하면 많은 질답을 찾을 수 있음    
1. 커뮤니티 설명글도 매우 많음    
1. 6개의 핵심 패키지 포함 23가지 패키지로 이루어진 메타 패키지    
1. tidy data 라는 사상과 파이프 연산자로 대동단결    
1. 사상에 영감을 받아 맞춰서 제작하는 개인 패키지가 많음(ex> [tidyquant](https://github.com/business-science/tidyquant), [tidytext](https://github.com/juliasilge/tidytext) 등)
]
.pull-right[
```{r}
if (!requireNamespace("tidyverse")){
  install.packages("tidyverse")}
library(tidyverse)
```
]
---
class: 
## tidy data 란

1. [Hadley Wickham](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)  2. [고감자님의 블로그](http://freesearch.pe.kr/archives/3942)  3. [헬로우데이터과학](http://www.hellodatascience.com/?p=287)


1.1 Each variable forms a column.    
1.2 각 변수는 개별의 열(column)으로 존재한다.    
1.3 각 열에는 개별 속성이 들어간다.    

2.1 Each observation forms a row.    
2.2 각 관측치는 행(row)를 구성한다.    
2.3 각 행에는 개별 관찰 항목이 들어간다.    

3.1 Each type of observational unit forms a table.    
3.2 각 테이블은 단 하나의 관측기준에 의해서 조직된 데이터를 저장한다.    
3.3 각 테이블에는 단일 유형의 데이터가 들어간다.    

.footnote[
  \* 출처 : [금융데이터 분석을 위한 R 입문][2]
]
---
class: 
## tidy data 란

![](http://garrettgman.github.io/images/tidy-1.png)

.footnote[
  \* 출처 : [Garrett Grolemund의 Data Science with R 블로그](http://garrettgman.github.io/tidying/)
]

---
class: 
## long form vs wide form

.pull-left[
### long form

1. 컴퓨터가 계산하기 좋은 모양
1. tidy data의 요건을 충족
1. tidyverse의 패키지 대부분의 입력 형태
]
.pull-right[
### wide form

1. 사람이 눈으로 보기 좋은 모양
1. 2개 변수에 대한 값만 확인 가능
1. dashboard 형이라고도 하며 조인 등 연산이 어려움
]

---

class: 

## tidy .blue[text] data 란

* a table with one-token-per-row    
* 한 행(row)에 한 토큰(token)으로 테이블을 구성해야 한다.

--

## 그럼 Token 이란?

글자 중 의미를 가진 단위를 총칭.    
tokenization은 가지고 있는 텍스트 자원을 token 단위로 나누는 것을 뜻함.     
ex> 자소(자음, 모음), 음소(글자), 형태소, 단어, n-gram 등

---
class: 

## [tidytext][tidytext] 패키지 소개

.pull-left[
* 한 행(row)에 한 토큰(token)으로 테이블을 구성하기 위한 패키지    
* 파이프 연산자를 지원    
* 여러 가지 token과 tm 패키지와의 호환 기능을 제공
* 자세히 소개하는 [온라인 사이트(영문)][tidytextmining]

  ```{r}
  if(!requireNamespace("tidytext")){
    install.packages("tidytext")
  }
  library(tidytext)
  ```

]
.pull-right[
  .center[
    [<img src=https://www.tidytextmining.com/images/cover.png width=60%>](http://amzn.to/2tZkmxG)
  ]
]

---
class: 

## 데이터 패키지 소개

### [presidentSpeechKr](https://forkonlp.github.io/presidentSpeechKr/)

대통령 기록 연구실의 대통령 연설문을 제공

```{r}
if(!requireNamespace("presidentSpeechKr")){
  remotes::install_github("forkonlp/presidentSpeechKr")
}
library(presidentSpeechKr)
```

---
class: 

## 대통령 조건 확인
```{r}
get_president()
```
--
class: 

## 연설 분야 조건 확인
```{r}
get_field()
```
---
class: 

## 연설 유형 확인
```{r}
get_event()
```

--
class: 

## 연설 리스트 데이터

```{r}
data(spidx)
str(spidx)
```

---

## 대통령 조건 연설 검색

```{r}
library(dplyr)
spidx %>% 
  filter(president == "윤보선")
```

---
class: 

## 연설문 텍스트 가져오기
```{r}
tar <- 
  spidx %>% 
  filter(president == "윤보선") %>% 
  select(link) %>% 
  top_n(1)
get_speech(tar)
```

---

## 연습문제

1. presidentSpeechKr 패키지에서 검색할 수 있는 대통령은 총 몇명인가요?

1. **윤보선** 대통령과 **박정희** 대통령은 각각 몇 개의 연설문이 있나요?

1. `nchar()` 함수는 글자수를 세주는 함수입니다. **최규하** 대통령의 취임사는 총 몇 글자 인가요?

---
class: center, middle, title-slide, 

## 단어 단위로 잘라보자!

---
class: 

## `unnest_tokens()` 함수

기본값인 단어 단위(특수문자 제거, 띄어쓰기 기준) token으로 동작.

```{r}
get_speech(tar) %>% 
  select(president, content) %>% 
  unnest_tokens(word, content)
```

---
class: 

## `unnest_tokens()` 함수 설명

텍스트 데이터를 token 단위로 풀어내는 함수

```{}
unnest_tokens(
  tbl = 텍스트 데이터,      # 다루고자 하는 텍스트 데이터 객체
  output = 결과열의 이름,   # token화의 결과가 작성될 열의 이름
  input = 목표 텍스트 열,   # 텍스트 데이터 객체 내의 텍스트 열
  token = "word",         # 기본값(띄어쓰기 단위)이 있어 생략 가능
  ...                     # 기타 옵션들
  )
```

---
class: 

```{r}
# 연설문 중 1개를 가져와서
get_speech(tar) %>%
  # 대통령 컬럼과 연설문 컬럼만 선택한 후
  select(president, content) %>% 
  # 연설문 컬럼을 word 단위로 쪼갠 결과물을 word라는 컬럼으로 출력
  unnest_tokens(word, content)
```

---

## 띄어쓰기 단위로 나눴을 때 문제점

.pull-left[
  .blue[**하다**]가 몇 가지 단어가 되는지    
  <https://namu.wiki/w/%ED%8C%8C%EC%9D%BC:M4nNWBR.png>
]

.pull-right[

  <img src=https://user-images.githubusercontent.com/6179259/45862373-5d2c2980-bdac-11e8-9247-3ebde14583e8.png width=60%>
]

---
class: 

## 한글의 특징 .yellow[형태소]

형태소란 : 의미를 가지는 최소 단위

> 철수가 밥을 먹었다.

```{r echo=FALSE}
library(KoNLP)
KoNLP::MorphAnalyzer("철수가 밥을 먹었다.")
```

---
class: 

.pull-left[![](https://github.com/haven-jeon/KoNLP/blob/master/etcs/figures/konlp_tags.png?raw=true)]
.pull-right[
  ### [크게 보기](https://github.com/haven-jeon/KoNLP/blob/master/etcs/figures/konlp_tags.png?raw=true)
  ### [여러 체계의 형태소 품사](https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0)
]

---
class: 

## R의 대표적인 형태소 분석기

.pull-left[
  ### RcppMeCab
  1. 일본어 형태소 분석기인 mecab 기반
  1. C++ 로 작성하여 속도가 매우 빠름
  1. 일본어, 중국어 등도 사용 가능
  1. 형태소 분석 함수를 제공
  1. 띄어쓰기에 덜 민감함
]
.pull-right[
  ### KoNLP
  1. 가장 유명한 형태소 분석기
  1. java로 작성된 한나눔 분석기 기반
  1. 우리샘, NiaDIC 등 자체 사전
  1. 텍스트 분석을 위한 기능들을 제공
  1. 친절한 [설명서](https://github.com/haven-jeon/KoNLP/blob/master/etcs/KoNLP-API.md)
]

---
class: center, middle, title-slide, 

## RcppMeCab 설치 확인

---
class: 

## RcppMeCab 실행

```{r}
library(RcppMeCab)
pos("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
```

---
class: center, middle, title-slide, 

## KoNLP 설치 확인

---
class: 

## KoNLP 실행

```{r}
library(KoNLP)
SimplePos09("롯데마트가 판매하고 있는 흑마늘 양념 치킨이 논란이 되고 있다.")
```

---

## 연습문제

1. **김영삼** 대통령의 첫 국무회의 연설문을 띄어쓰기 단위로 자르면 총 몇 단어인가요?

1. **노태우** 대통령의 취임사를 `RcppMeCab` 패키지로 형태소 분석한 결과를 출력하세요.

1. **김대중** 대통령의 취임사를 `KoNLP` 패키지의 `SimplePos09()` 함수로 형태소 분석한 결과를 출력하세요.

---

## 복습

---

## 준비

```{r}
library(tidytext)
library(dplyr)
library(presidentSpeechKr)
tar <- 
  spidx %>% 
  filter(president == "이명박") %>% 
  arrange(date) %>% 
  select(link) %>% 
  top_n(1)
```

---
class: 

## `unnest_tokens()` 함수 설명

텍스트 데이터를 token 단위로 풀어내는 함수

```{}
unnest_tokens(
  tbl = 텍스트 데이터,      # 다루고자 하는 텍스트 데이터 객체
  output = 결과열의 이름,   # token화의 결과가 작성될 열의 이름
  input = 목표 텍스트 열,   # 텍스트 데이터 객체 내의 텍스트 열
  token = "word",         # 기본값(띄어쓰기 단위)이 있어 생략 가능
  ...                     # 기타 옵션들
  )
```

---

## 연설문 여러 개 가져오기

```{r}
# 연설문 중 1개를 가져와서
get_speech(tar) %>%
  # 대통령 컬럼과 연설문 컬럼만 선택한 후
  select(president, content) %>% 
  # 연설문 컬럼을 word 단위로 쪼갠 결과물을 word라는 컬럼으로 출력
  unnest_tokens(word, content)
```

---
class: 

## R의 대표적인 형태소 분석기

.pull-left[
  ### RcppMeCab
  1. 일본어 형태소 분석기인 mecab 기반
  1. C++ 로 작성하여 속도가 매우 빠름
  1. 일본어, 중국어 등도 사용 가능
  1. 형태소 분석 함수를 제공
  1. 띄어쓰기에 덜 민감함
]
.pull-right[
  ### KoNLP
  1. 가장 유명한 형태소 분석기
  1. java로 작성된 한나눔 분석기 기반
  1. 우리샘, NiaDIC 등 자체 사전
  1. 텍스트 분석을 위한 기능들을 제공
  1. 친절한 [설명서](https://github.com/haven-jeon/KoNLP/blob/master/etcs/KoNLP-API.md)
]

---

## 형태소 분석기화 함께 사용하기

```{}
unnest_tokens(
  tbl = 텍스트 데이터,      
  output = 결과열의 이름,   
  input = 목표 텍스트 열,   
  token = "word",         <---- 여기에 형태소 분석 함수를 적용
  ...                     
  )
```

---

```{r}
library(RcppMeCab)
# 연설문 중 1개를 가져와서
(get_speech(tar) %>%
  # 대통령 컬럼과 연설문 컬럼만 선택한 후
  select(president, content) %>% 
  # 연설문 컬럼을 형태소 단위로 쪼갠 결과물을 pos라는 컬럼으로 출력
  unnest_tokens(pos, content, token=pos) -> pos_res)
```

---

.pull-left[![](https://github.com/haven-jeon/KoNLP/blob/master/etcs/figures/konlp_tags.png?raw=true)]
.pull-right[
  ### [크게 보기](https://github.com/haven-jeon/KoNLP/blob/master/etcs/figures/konlp_tags.png?raw=true)
  ### [여러 체계의 형태소 품사](https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0)
]


---

## 필요한 내용

1. 명사(N), 동사(VV), 형용사(VA)

```{r}
pos_res %>% 
  filter(grepl("/n|/vv|/va", pos)) %>% 
  mutate()
```



---

단어 기반 지표 설명

---

워드 클라우드

---

### 폴더 내의 파일 한 번에 불러오기

```
library(fs)
library(tidyverse)
"data_dir" %>% 
  fs::dir_ls(regexp = "\\.csv$") %>% 
  purrr::map_dfr(readr::read_csv, .id = "source") %>% 
  dplyr::mutate(Month_Year = lubridate::myd(Month_Year, truncated = 1))
```

[출처](https://mrchypark.github.io/post/%EB%B2%88%EC%97%AD-%ED%8F%B4%EB%8D%94%EC%95%88%EC%9D%98-csv-%ED%8C%8C%EC%9D%BC%EB%93%A4%EC%9D%84-purrr-%EC%99%80-readr-%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%B4%EC%84%9C-%ED%95%9C%EB%B0%A9%EC%97%90-%EB%B6%88%EB%9F%AC%EC%98%A4%EA%B8%B0/)

---

단어 정규화 > 비슷한 뜻의 단어들은 어떻게 합치나

단어 점수화

예시 프로젝트 진행
뭐냐면...



[1]: https://github.com/tidyverse/tidyverse
[2]: https://mrchypark.github.io/kisa_finR
[tidytextmining]: https://www.tidytextmining.com/
[tidytext]: https://juliasilge.github.io/tidytext/